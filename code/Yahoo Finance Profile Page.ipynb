{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96076cd8",
   "metadata": {},
   "source": [
    "# Get the Company List\n",
    "\n",
    "Work flow:\n",
    "1. read the company list `txt` file;\n",
    "2. get the symbols;\n",
    "3. put them together <sup>[[1]](#ft1)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b10563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def get_industry_list() -> list:\n",
    "    root_path = os.path.abspath(os.path.dirname(os.getcwd()))\n",
    "    data_path = os.path.join(root_path, 'data')\n",
    "    txt_pattern = re.compile('\\w+(?=.txt)')\n",
    "    names = []\n",
    "    for file in os.listdir(data_path):\n",
    "        if file.endswith('.txt'):\n",
    "            file = re.search(txt_pattern, file)[0]\n",
    "            names.append(file)\n",
    "    return names\n",
    "\n",
    "def get_company_list(l: list) -> dict:\n",
    "    root_path = os.path.abspath(os.path.dirname(os.getcwd()))\n",
    "    data_path = os.path.join(root_path, 'data')\n",
    "    comp = dict()\n",
    "    for n in l:\n",
    "        file_name = n + '.txt' \n",
    "        path = os.path.join(data_path, file_name)\n",
    "        # read the txt file\n",
    "        with open(path, 'r') as f:\n",
    "            f = f.readlines()\n",
    "        # identify the symbol pattern of the company\n",
    "        pattern = re.compile('(?<=^)[A-Z0-9-.&]+(?=\\t)')\n",
    "\n",
    "        company_list = []\n",
    "        # get the company list\n",
    "        for line in f:\n",
    "            company_list.extend(re.findall(pattern, line)) \n",
    "        comp[n] = company_list\n",
    "    return comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03586f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "industry = get_industry_list()\n",
    "comps = get_company_list(industry)\n",
    "print('data is ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4b3a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "comps['agriculture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ce2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "comps['energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35989532",
   "metadata": {},
   "outputs": [],
   "source": [
    "comps['travel']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d474f",
   "metadata": {},
   "source": [
    "# Get the Profile Page for Each Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import requests\n",
    "import random\n",
    "        \n",
    "def get_profile(inds: str, d: dict):\n",
    "    \"\"\"\n",
    "    get profile for one industry\n",
    "    \"\"\"\n",
    "    assert inds in d.keys(), 'This industry is not in the list for now.'\n",
    "    root_path = os.path.abspath(os.path.dirname(os.getcwd()))\n",
    "    web_path = os.path.join(root_path, 'webpage')\n",
    "    inds_path = os.path.join(web_path, inds)\n",
    "    try:\n",
    "        # REF: https://www.geeksforgeeks.org/create-a-directory-in-python/\n",
    "        os.mkdir(inds_path) # create the corresponding industry direction\n",
    "    except:\n",
    "        pass\n",
    "    headers = {'User-agent': 'Mozilla/5.0'}\n",
    "    count = 0\n",
    "    total = len(d[inds]) - len(os.listdir(inds_path))\n",
    "    t1 = time.time()\n",
    "    for c in d[inds]:\n",
    "        file_name = c + '.txt'\n",
    "        if file_name in os.listdir(inds_path):\n",
    "            continue\n",
    "        else:  \n",
    "            count += 1\n",
    "            file_path = os.path.join(inds_path, file_name)\n",
    "            url = (\"https://finance.yahoo.com/quote/{}/profile?p={}\".format(s,s))\n",
    "            num = random.randint(3, 15)\n",
    "            time.sleep(num) # sleep num's for each request\n",
    "            webpage = requests.get(url, headers=headers)\n",
    "            with open(file_path, 'w') as file:\n",
    "                file.write(webpage.text)\n",
    "        t2 = time.time()\n",
    "        print('Progress {c}/{t}.'.format(c = count, t = total))\n",
    "        print('Have cost {t:.3f} seconds; average cost time {s:.3f} seconds'.format(t = t2 - t1, s = (t2-t1)/count))\n",
    "        print('Estimated time to complete {t:.3f} mins.'.format(t = (total-count)*(t2-t1)/count/60))\n",
    "        print('\\n')\n",
    "    return\n",
    "    \n",
    "def get_all_profile(d: dict):\n",
    "    for k in d.keys():\n",
    "        get_profile(k, d)\n",
    "        print('\\n\\n\\n {i} is done'.format{i = k})\n",
    "        \n",
    "    print('\\n\\n\\nall done.') \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c6c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_profile(comps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca9f294",
   "metadata": {},
   "source": [
    "# Parse the Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as BeautifulSoup \n",
    "import re\n",
    "\n",
    "def parse_page(i: str) -> dict:\n",
    "    \"\"\"\n",
    "    parse one industry pages and extract the full name, location, website, section, industry for each company\n",
    "    Input:\n",
    "        i = industry name\n",
    "    Output:\n",
    "        dictionary = {company:{name:, location:, webstion:, section:, industry:,}}\n",
    "    \"\"\"\n",
    "    # access the dir\n",
    "    root_path = os.path.abspath(os.path.dirname(os.getcwd()))\n",
    "    web_path = os.path.join(root_path, 'webpage')\n",
    "    assert inds in os.listdir(web_path), 'This industry is not supported.'\n",
    "    inds_path = os.path.join(web_path, inds)\n",
    "    \n",
    "    # read file and parse each\n",
    "    c_pattern = re.compile('\\w+(?=.txt)')\n",
    "    result = dict()\n",
    "    for f in os.listdir(inds_path):\n",
    "        if not f.endswith('.txt'): # avoid _DS.Store\n",
    "            continue\n",
    "        vals = {}\n",
    "        c = re.search(c_pattern, f)[0] # get company name\n",
    "        url = (\"https://finance.yahoo.com/quote/{}/profile?p={}\".format(c,c)) # profile page\n",
    "        file_path = os.path.join(inds_path, f)\n",
    "        with open(file_path, 'r') as webpage:\n",
    "            soup = webpage.read()\n",
    "            \n",
    "        soup = BeautifulSoup.BeautifulSoup(soup)\n",
    "        \n",
    "        # get the company full name\n",
    "        name = str(soup.find(class_=\"Fz(m) Mb(10px)\"))\n",
    "        name_p = re.compile('(?<=data-reactid=\"6\">).+(?=</h3>)')\n",
    "        try:\n",
    "            name = re.findall(name_p, name)[0]\n",
    "        except:\n",
    "            print(c, name)\n",
    "            print(url)\n",
    "            print('\\n')\n",
    "            result[c] = vals\n",
    "            continue\n",
    "\n",
    "        # get the company address and website address\n",
    "        address = str(soup.find(class_=\"D(ib) W(47.727%) Pend(40px)\"))\n",
    "        location_p = re.compile('(?<=-->)[\\d\\w\\s,]+(?=<!--)')\n",
    "        location = re.findall(location_p, address)\n",
    "        website_p = re.compile('(?<=target=\"_blank\" title=\"\">).+(?=</a></p>)')\n",
    "        website = re.findall(website_p, address)\n",
    "        if website:\n",
    "            website = website[0]\n",
    "        \n",
    "        # get the section and industry along with\n",
    "        info = str(soup.find(class_=\"D(ib) Va(t)\"))\n",
    "        section_p1 = re.compile('(?<=data-reactid=\"21\">).+(?=</span><br data-reactid=\"22\"/>)')\n",
    "        section_p2 = re.compile('(?<=data-reactid=\"23\">).+(?=</span><br data-reactid=\"24\"/>)')\n",
    "        if re.findall(section_p1, info):\n",
    "            section = re.findall(section_p1, info)[0]\n",
    "        else:\n",
    "            section = re.findall(section_p2, info)[0]\n",
    "        industry_p1 = re.compile('(?<=data-reactid=\"25\">).+(?=</span><br data-reactid=\"26\"/>)')\n",
    "        industry_p2 = re.compile('(?<=data-reactid=\"27\">).+(?=</span><br data-reactid=\"28\"/>)')\n",
    "        if re.findall(industry_p1, info):\n",
    "            industry = re.findall(industry_p1, info)[0]\n",
    "        else:\n",
    "            industry = re.findall(industry_p2, info)[0]\n",
    "\n",
    "        vals['name'] = name\n",
    "        vals['location'] = location\n",
    "        vals['website'] = website\n",
    "        vals['section'] = section\n",
    "        vals['industry'] = industry\n",
    "        vals['profile'] = url\n",
    "        result[c] = vals\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657188af",
   "metadata": {},
   "source": [
    "# Footnote\n",
    "\n",
    "<a name=\"ft1\">[1]</a>: Difference between `os.wal` and `os.listdir` https://www.cnblogs.com/cloud-ken/p/10017093.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
