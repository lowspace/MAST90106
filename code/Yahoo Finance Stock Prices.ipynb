{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Data from Yahoo Fiance Remotely For One Stock\n",
    "\n",
    "Using package `pandas_datareader` to read data remotely: <sup>[[1]](#ft1)</sup>\n",
    "+ use `pip install pandas_datareader` to install `pandas_datareader` in shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.128844\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# REF: https://pandas.pydata.org/pandas-docs/version/0.18.1/remote_data.html#remote-data-yahoo\n",
    "# Install pandas_datareader first.\n",
    "import pandas_datareader.data as web\n",
    "import datetime \n",
    "\n",
    "t1 = datetime.datetime.now()\n",
    "start = datetime.datetime(1970,1,1)\n",
    "end = datetime.date.today()\n",
    "# read data from Yahoo Fiance Remotely\n",
    "# for i in range(10):\n",
    "BHP = web.DataReader(\"BHP\", \"yahoo\", start, end)\n",
    "t2 = datetime.datetime.now()\n",
    "print((t2 - t1)/10) # test which proxy routine is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Obtain the Company List of an Industry\n",
    "\n",
    "1. Website: https://finance.yahoo.com/sector/ms_basic_materials\n",
    "2. Select the filter\n",
    "3. Copy the list to txt, and get the company name via regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "def get_industry_data(path: str, start: datetime.datetime, end: datetime.datetime):\n",
    "    '''\n",
    "    Description: read the txt file and extract the names of the companies, then obtain the history stock prices\n",
    "                      from 1970,1,1 to 2021,1,1.\n",
    "    Input:\n",
    "        path = the path of the txt file\n",
    "        start = start time\n",
    "        end = end time\n",
    "    Output:\n",
    "        a dictionary {company_name: pd.dataframe(history stock prices)}\n",
    "    '''\n",
    "    # read the txt file\n",
    "    with open(path, 'r') as f:\n",
    "        f = f.readlines()\n",
    "    # identify the symbol pattern of the company\n",
    "    pattern = re.compile('(?<=^)[A-Z0-9-.&]+(?=\\t)')\n",
    "    \n",
    "    company_list = []\n",
    "    # get the company list\n",
    "    for line in f:\n",
    "        company_list.extend(re.findall(pattern, line)) \n",
    "        \n",
    "    company_dict = defaultdict(pd.core.frame.DataFrame)\n",
    "    for c in company_list:\n",
    "        # read data from Yahoo Fiance Remotely\n",
    "        try:\n",
    "            company_dict[c] = web.DataReader(c, \"yahoo\", start, end)\n",
    "#             print(c, 'complete')\n",
    "        except:\n",
    "            print(c)\n",
    "        \n",
    "    return company_dict\n",
    "\n",
    "def to_csv(d: dict, folder: str):\n",
    "    \"\"\"\n",
    "    Store the company data into csv file\n",
    "    Input:\n",
    "        d = the company dictionary\n",
    "        folder = the path to store these file\n",
    "    Output:\n",
    "        many csv files, each one corresponds to a company historical stock prices\n",
    "    \"\"\"\n",
    "    \n",
    "    # store the data into data folder\n",
    "    # REF: https://www.jianshu.com/p/dde02a88a5c1\n",
    "    root_path = os.path.abspath(os.path.dirname(os.getcwd()))\n",
    "    data_path = os.path.join(root_path, 'data')\n",
    "    path = os.path.join(data_path, folder)\n",
    "    try:\n",
    "        # REF: https://www.geeksforgeeks.org/create-a-directory-in-python/\n",
    "        os.mkdir(path) # create the corresponding industry direction\n",
    "    except:\n",
    "        # empty the previous folder\n",
    "        for f in os.listdir(path):\n",
    "            os.remove(os.path.join(path, f))\n",
    "    for k,v in d.items():\n",
    "        file = path + '/' + k + '.csv' # file location\n",
    "        v.to_csv(path_or_buf = file, index = True)\n",
    "        \n",
    "def get_url():\n",
    "    '''\n",
    "    get the url of the companies to check whether they don't have data prior to 2021.1.1\n",
    "    Input: a list of company names\n",
    "    Output: the markdown style url link\n",
    "    '''\n",
    "    text = str(input('company'))\n",
    "    text = text.split(' ')\n",
    "    for t in text:\n",
    "        url = \"https://finance.yahoo.com/quote/NAME/history?p=NAME\"\n",
    "        p = re.compile('NAME')\n",
    "        url = re.sub(p, t, url)\n",
    "        print('+ [{c}]({u})'.format(c = t, u = url))\n",
    "\n",
    "start = datetime.datetime(1970,1,1) # start time point \n",
    "end = datetime.datetime(2021,1,1) # end time point\n",
    "root_path = os.path.abspath(os.path.dirname(os.getcwd()))\n",
    "data_path = os.path.join(root_path, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agriculture\n",
    "\n",
    "<!-- ![](https://user-images.githubusercontent.com/22797017/116096274-bb93b400-a6db-11eb-824d-94c837ef181c.png) -->\n",
    "![](https://user-images.githubusercontent.com/22797017/116341107-ecc2d000-a812-11eb-8a15-21a47afcc38e.png)\n",
    "\n",
    "<!-- The following companies do not have the data prior to 2021-01-01:\n",
    "+ [PPTA](https://finance.yahoo.com/quote/PPTA/history?p=PPTA)\n",
    "+ [CNEY](https://finance.yahoo.com/quote/CNEY/history?p=CNEY)\n",
    "+ [HUDI](https://finance.yahoo.com/quote/HUDI/history?p=HUDI)\n",
    "+ [CRKN](https://finance.yahoo.com/quote/CRKN/history?p=CRKN)\n",
    "+ [ZY](https://finance.yahoo.com/quote/ZY/history?p=ZY) -->\n",
    "\n",
    "Companies: \n",
    "```\n",
    "YTEN; RKDA; CGA; SEED; MBII; IPI; AVD; UAN; MGPI; ICL; CF; SMG; MOS; FMC; NTR; CTVA; CTA-PA; CTA-PB;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is ready.\n"
     ]
    }
   ],
   "source": [
    "agri_dict = get_industry_data(os.path.join(data_path, 'agriculture.txt'), start, end)\n",
    "print('data is ready.')\n",
    "# to_csv(agri_dict, 'agriculture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company\n",
      "+ [](https://finance.yahoo.com/quote//history?p=)\n"
     ]
    }
   ],
   "source": [
    "get_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'YTEN; RKDA; CGA; SEED; MBII; IPI; AVD; UAN; MGPI; ICL; CF; SMG; MOS; FMC; NTR; CTVA; CTA-PA; CTA-PB; '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = ''\n",
    "for k in agri_dict.keys():\n",
    "    t = k + '; ' + t\n",
    "    \n",
    "print(len(agri_dict.keys()))\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy\n",
    "\n",
    "![](https://user-images.githubusercontent.com/22797017/115959053-e398e100-a53c-11eb-9161-db98a1c912d6.png)\n",
    "\n",
    "The following companies do not have the data prior to 2021-01-01<sup>[[2]](#ft2)</sup>:\n",
    "+ [CSAN](https://finance.yahoo.com/quote/CSAN/history?p=CSAN)\n",
    "+ [CHK](https://finance.yahoo.com/quote/CHK/history?p=CHK)\n",
    "+ [DEN](https://finance.yahoo.com/quote/DEN/history?p=DEN)\n",
    "+ [XOG](https://finance.yahoo.com/quote/XOG/history?p=XOG)\n",
    "+ [VEI](https://finance.yahoo.com/quote/VEI/history?p=VEI)\n",
    "+ [AMR](https://finance.yahoo.com/quote/AMR/history?p=AMR)\n",
    "+ [GLP-PB](https://finance.yahoo.com/quote/GLP-PB/history?p=GLP-PB)\n",
    "\n",
    "Otherwise:\n",
    "```\n",
    "GMLPP; GLP-PA; TGP-PB; DLNG-PA; DCP-PC; NS-PA; ALIN-PB; ALIN-PE; CEQP-P; HMLP-PA; GLOP-PA; EP-PC; TGP-PA; ALIN-PA; NS-PC; DCP-PB; MTR; MARPS; ICD; CELP; IO; NRT; PVL; PHX; DWSN; NNA; CRT; MVO; NINE; GIFI; VOC; PRT; BPT; DLNG-PB; KLXE; SMLP; RNGR; CCLP; MMLP; AMPY; DLNG; EXTN; FTK; FET; SND; SBOW; GEOS; NGS; GLOP; EGY; SD; NC; TNP; PBT; RNET; TUSK; OSG; VIST; SJT; NRP; BORR; NGL; NR; CEIX; TNP-PF; TNP-PD; TNP-PE; TK; TTI; NOA; PDS; OIS; DSSI; HESM; LPI; BTU; WTI; SGU; TNK; CLMT; SOI; REX; PVAC; BRY; WTTR; SBR; DMLP; ESTE; TDW; HMLP; SRLP; GLOG; NBR-PA; NVGS; KRP; NBR; TRMD; FLNG; BCEI; LPG; TGS; HLX; NEX; MRC; ARCH; OMP; GLP; BOOM; FI; CAPL; PARR; VTOL; SLCA; ARLP; MNRL; TALO; NGL-PB; PBFX; GLOP-PB; GLOP-PC; PUMP; NGL-PC; GPRK; DRQ; DHT; RES; OII; DNOW; VET; KOS; STNG; CRK; ERF; GEL; PTEN; CLB; GLNG; NBLX; TGP; CPE; WLL; GLOG-PA; BPMP; AROC; OAS; FRO; YPF; USAC; PBF; DK; EURN; RTLR; DKL; PAGP; LBRT; SM; CRC; CPG; RIG; CVI; NS; CLNE; BSM; INT; HEP; WHD; CEQP; RRC; REGI; AR; MUR; ENLC; SWN; MGY; HP; VNOM; MTDR; NS-PB; CNX; ENBL; FTI; SUN; PDCE; ETRN; CHX; UGP; AM; NFG; DCP; EQT; NOV; VVV; SHI; HFC; OVV; SHLX; XEC; COG; CCJ; PAA; APA; TRGP; PSXP; WES; MRO; CLR; MMP; SSL; TPL; FANG; TS; DVN; CVE; PBA; HAL; HES; BKR; ET; OKE; OXY; EC; MPLX; VLO; WMB; SU; PXD; PSX; MPC; CNQ; SLB; KMI; EOG; E; TRP; EPD; PBR; PBR-A; EQNR; COP; ENB; SNP; BP; TOT; PTR; RDS-B; RDS-A; CVX; XOM;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSAN\n",
      "CHK\n",
      "DEN\n",
      "XOG\n",
      "VEI\n",
      "AMR\n",
      "GLP-PB\n",
      "data is ready.\n"
     ]
    }
   ],
   "source": [
    "energy_dict = get_industry_data(os.path.join(data_path, 'energy.txt'), start, end)\n",
    "print('data is ready.')\n",
    "# to_csv(energy_dict, 'energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'GMLPP; GLP-PA; TGP-PB; DLNG-PA; DCP-PC; NS-PA; ALIN-PB; ALIN-PE; CEQP-P; HMLP-PA; GLOP-PA; EP-PC; TGP-PA; ALIN-PA; NS-PC; DCP-PB; MTR; MARPS; ICD; CELP; IO; NRT; PVL; PHX; DWSN; NNA; CRT; MVO; NINE; GIFI; VOC; PRT; BPT; DLNG-PB; KLXE; SMLP; RNGR; CCLP; MMLP; AMPY; DLNG; EXTN; FTK; FET; SND; SBOW; GEOS; NGS; GLOP; EGY; SD; NC; TNP; PBT; RNET; TUSK; OSG; VIST; SJT; NRP; BORR; NGL; NR; CEIX; TNP-PF; TNP-PD; TNP-PE; TK; TTI; NOA; PDS; OIS; DSSI; HESM; LPI; BTU; WTI; SGU; TNK; CLMT; SOI; REX; PVAC; BRY; WTTR; SBR; DMLP; ESTE; TDW; HMLP; SRLP; GLOG; NBR-PA; NVGS; KRP; NBR; TRMD; FLNG; BCEI; LPG; TGS; HLX; NEX; MRC; ARCH; OMP; GLP; BOOM; FI; CAPL; PARR; VTOL; SLCA; ARLP; MNRL; TALO; NGL-PB; PBFX; GLOP-PB; GLOP-PC; PUMP; NGL-PC; GPRK; DRQ; DHT; RES; OII; DNOW; VET; KOS; STNG; CRK; ERF; GEL; PTEN; CLB; GLNG; NBLX; TGP; CPE; WLL; GLOG-PA; BPMP; AROC; OAS; FRO; YPF; USAC; PBF; DK; EURN; RTLR; DKL; PAGP; LBRT; SM; CRC; CPG; RIG; CVI; NS; CLNE; BSM; INT; HEP; WHD; CEQP; RRC; REGI; AR; MUR; ENLC; SWN; MGY; HP; VNOM; MTDR; NS-PB; CNX; ENBL; FTI; SUN; PDCE; ETRN; CHX; UGP; AM; NFG; DCP; EQT; NOV; VVV; SHI; HFC; OVV; SHLX; XEC; COG; CCJ; PAA; APA; TRGP; PSXP; WES; MRO; CLR; MMP; SSL; TPL; FANG; TS; DVN; CVE; PBA; HAL; HES; BKR; ET; OKE; OXY; EC; MPLX; VLO; WMB; SU; PXD; PSX; MPC; CNQ; SLB; KMI; EOG; E; TRP; EPD; PBR; PBR-A; EQNR; COP; ENB; SNP; BP; TOT; PTR; RDS-B; RDS-A; CVX; XOM; '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = ''\n",
    "for k in energy_dict.keys():\n",
    "    t = k + '; ' + t\n",
    "\n",
    "print(len(energy_dict.keys()))\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transportation\n",
    "\n",
    "![](https://user-images.githubusercontent.com/22797017/115959990-99fec500-a541-11eb-89cd-19ff40f4771e.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travel\n",
    "\n",
    "![](https://user-images.githubusercontent.com/22797017/116093914-a9187b00-a6d9-11eb-8348-722caa8ce235.png)\n",
    "\n",
    "The following companies do not have the data prior to 2021-01-01:\n",
    "\n",
    "+ [EASEMYTRIP.NS](https://finance.yahoo.com/quote/EASEMYTRIP.NS/history?p=EASEMYTRIP.NS)\n",
    "+ [NNAX](https://finance.yahoo.com/quote/NNAX/history?p=NNAX)\n",
    "+ [61T.F](https://finance.yahoo.com/quote/61T.F/history?p=61T.F)\n",
    "+ [CLVB.DU](https://finance.yahoo.com/quote/CLVB.DU/history?p=CLVB.DU)\n",
    "+ [LI4.MU](https://financeLI4.MUyahooLI4.MUcom/quote/LI4.MU/history?p=LI4.MU)\n",
    "+ [9961.HK](https://finance.yahoo.com/quote/9961.HK/history?p=9961.HK)\n",
    "+ [CLVB.MU](https://finance.yahoo.com/quote/CLVB.MU/history?p=CLVB.MU)\n",
    "+ [CLVB.F](https://finance.yahoo.com/quote/CLVB.F/history?p=CLVB.F)\n",
    "+ [26Y.F](https://finance.yahoo.com/quote/26Y.F/history?p=26Y.F)\n",
    "+ [LI4.DU](https://finance.yahoo.com/quote/LI4.DU/history?p=LI4.DU)\n",
    "+ [0TUA.DU](https://finance.yahoo.com/quote/0TUA.DU/history?p=0TUA.DU)\n",
    "+ TUI1.HM\n",
    "\n",
    "Otherwise:\n",
    "```\n",
    "LAG.SG; FLI.BE; 1NC.BE; PCE1.HM; E3X1.DU; 1NC.DU; 09B.BE; T6A.HM; TUI1.HM; MY1.BE; 1NC.HM; E3X1.MU; WBJ.BE; RC8.BE; E3X1.BE; E3X1.SG; 1NC.SG; E3X1.HM; PCE1.MU; TUI2.BE; WBJ.MU; TUI2.MU; CLV.DU; DG1.BE; T6A.MU; RC8.SG; CG6C.BE; CVC1.DU; 0HB2.IL; 1C6.SG; HOC.SG; 0W2Y.IL; PCE1.DU; CLV.MU; TXM1.MU; T6A.DU; CVC1.HM; 0TUA.BE; 1481.KL; 6NIQ.BE; 0022.KL; 4ZO0.F; E3X1.HA; PCE1.HA; TUI1.SG; T6A.SG; LAG.BE; 09B.DU; RC8.DU; HOC.MU; 09B.MU; HOC.HM; CLV.BE; PCE1.BE; TVD6.BE; LAG.HM; LAG.MU; TVD6.DU; TEM.BE; TXM1.BE; WBJ.HM; PCE1.SG; WBJ.SG; 9113.KL; E3X1.DE; 0I50.IL; HOC.DU; TUI1.MU; 0TUA.SG; RC8.MU; 0TUA.MU; HOC.BE; 1NC.HA; 5016.KL; TVD6.SG; PCE1.DE; 1NC.MU; CVC1.SG; T6A.BE; TUI1.HA; TXM1.SG; CVC1.BE; TUI1.DU; DG1.MU; LAG.DU; D3G.SG; MY1.SG; TUI1.BE; 6T8.MU; T6A.HA; CVC1.HA; LAG.HA; WESC; 5IH.F; A8N.MU; PSA.MI; SOS.MI; ONVC; ZMA.V; ASWN.SW; NTU1L.VS; JAY.AX; MKGI; CROWNTOURS.BO; FLAP.IS; LRG.SG; AVIA.TA; TVD6.F; 26Y.SG; HOC.F; YTRA; HSW.F; 1TJ.F; HSW.IR; 1235.HK; HOC.DE; 8668.HK; TRZ.TO; TZOO; ID9.F; 8069.HK; COX&KINGS.NS; TRRB; VMV.BO; COX&KINGS.BO; 1620.HK; 1701.HK; 0TUA.F; HLO.AX; 6882.HK; ALVDM.PA; 09B.F; TOUR; 2719.TWO; ITHL.BO; LMN.SW; 1901.HK; EDR.MC; MIN.L; 8095.HK; 2743.TWO; 2745.TWO; 0487.HK; 2734.TWO; LI4.F; 9BP.F; D3G.F; LIND; 0265.HK; DESP; 6242.TWO; ISTA.TA; WBJ.F; 600706.SS; 6T8.F; 1C6.F; 1745.HK; WEB.AX; 9376.T; 300178.SZ; MY1.F; 002159.SZ; FLI.F; 603099.SS; 603199.SS; 2T9A.F; 5706.TW; CTD.AX; MMYT; DG1.F; DRTGF; MMB.PA; 6577.T; NTHOL.IS; LAG.F; 000888.SZ; FLT.AX; TEM.F; 1810.SR; TEM.DU; CVCB3.SA; 300859.SZ; TUI2.F; 6548.T; TUI2.SG; TUI1.F; TUI1.DE; 002707.SZ; TNL; TRIP.MI; T6A.F; T6A.DE; TRIP.VI; TUIFF; 2731.TW; TUIFY; TRIP; TENG.L; NCLH.VI; 1NC.F; 000796.SZ; 6561.T; NCLH; 9085.S; THOMASCOOK.BO; HSW.L; 1992.HK; PGJO.JK; RC8.F; THOMASCOOK.NS; CLV.F; 7048.T; RCL; EXPE.VI; E3X1.F; TCOM; EXPE; CVC1.F; 9726.T; CCL; T1RI34.SA; YELO.JK; 6030.T; 0780.HK; 6191.T; N1CL34.SA; OTB.L; BOOK.VI; PCE1.F; DESP.BA; BKNG; R1CL34.SA; TRIP.MX; EXGR34.SA; CRIP34.SA; NCLHN.MX; C1CL34.SA; PANR.JK; PDES.JK; TRN.L; BAYU.JK; RCL.MX; TUI.L; EXPE.MX; BKNG34.SA; 601888.SS; TRIP.BA; 039130.KS; 032350.KS; SONA.JK; BKNG.MX;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EASEMYTRIP.NS\n",
      "NNAX\n",
      "61T.F\n",
      "CLVB.DU\n",
      "LI4.MU\n",
      "9961.HK\n",
      "CLVB.MU\n",
      "CLVB.F\n",
      "26Y.F\n",
      "LI4.DU\n",
      "0TUA.DU\n",
      "TUI1.HM\n",
      "data is ready.\n"
     ]
    }
   ],
   "source": [
    "travel_dict = get_industry_data(os.path.join(data_path, 'travel.txt'), start, end)\n",
    "print('data is ready.')\n",
    "# to_csv(travel_dict, 'travel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "companyEASEMYTRIP.NS NNAX 61T.F CLVB.DU LI4.MU 9961.HK CLVB.MU CLVB.F 26Y.F LI4.DU 0TUA.DU TUI1.HM\n",
      "+ [EASEMYTRIP.NS](https://finance.yahoo.com/quote/EASEMYTRIP.NS/history?p=EASEMYTRIP.NS)\n",
      "+ [NNAX](https://finance.yahoo.com/quote/NNAX/history?p=NNAX)\n",
      "+ [61T.F](https://finance.yahoo.com/quote/61T.F/history?p=61T.F)\n",
      "+ [CLVB.DU](https://finance.yahoo.com/quote/CLVB.DU/history?p=CLVB.DU)\n",
      "+ [LI4.MU](https://finance.yahoo.com/quote/LI4.MU/history?p=LI4.MU)\n",
      "+ [9961.HK](https://finance.yahoo.com/quote/9961.HK/history?p=9961.HK)\n",
      "+ [CLVB.MU](https://finance.yahoo.com/quote/CLVB.MU/history?p=CLVB.MU)\n",
      "+ [CLVB.F](https://finance.yahoo.com/quote/CLVB.F/history?p=CLVB.F)\n",
      "+ [26Y.F](https://finance.yahoo.com/quote/26Y.F/history?p=26Y.F)\n",
      "+ [LI4.DU](https://finance.yahoo.com/quote/LI4.DU/history?p=LI4.DU)\n",
      "+ [0TUA.DU](https://finance.yahoo.com/quote/0TUA.DU/history?p=0TUA.DU)\n",
      "+ [TUI1.HM](https://finance.yahoo.com/quote/TUI1.HM/history?p=TUI1.HM)\n"
     ]
    }
   ],
   "source": [
    "get_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LAG.SG; FLI.BE; 1NC.BE; PCE1.HM; E3X1.DU; 1NC.DU; 09B.BE; T6A.HM; MY1.BE; 1NC.HM; E3X1.MU; WBJ.BE; RC8.BE; E3X1.BE; E3X1.SG; 1NC.SG; E3X1.HM; PCE1.MU; TUI2.BE; WBJ.MU; TUI2.MU; CLV.DU; DG1.BE; T6A.MU; RC8.SG; CG6C.BE; CVC1.DU; 0HB2.IL; 1C6.SG; HOC.SG; 0W2Y.IL; PCE1.DU; CLV.MU; TXM1.MU; T6A.DU; CVC1.HM; 0TUA.BE; 1481.KL; 6NIQ.BE; 0022.KL; 4ZO0.F; E3X1.HA; PCE1.HA; TUI1.SG; T6A.SG; LAG.BE; 09B.DU; RC8.DU; HOC.MU; 09B.MU; HOC.HM; CLV.BE; PCE1.BE; TVD6.BE; LAG.HM; LAG.MU; TVD6.DU; TEM.BE; TXM1.BE; WBJ.HM; PCE1.SG; WBJ.SG; 9113.KL; E3X1.DE; 0I50.IL; ZMWYD; HOC.DU; TUI1.MU; 0TUA.SG; RC8.MU; 0TUA.MU; HOC.BE; 1NC.HA; 5016.KL; TVD6.SG; TVD6.MU; PCE1.DE; 1NC.MU; CVC1.SG; T6A.BE; TUI1.HA; TXM1.SG; CVC1.BE; TUI1.DU; DG1.MU; LAG.DU; D3G.SG; MY1.SG; TUI1.BE; 6T8.MU; T6A.HA; CVC1.HA; LAG.HA; WESC; 5IH.F; A8N.MU; PSA.MI; SOS.MI; ONVC; ZMA.V; ASWN.SW; NTU1L.VS; JAY.AX; 6NIQ.F; MKGI; CROWNTOURS.BO; FLAP.IS; LRG.SG; AVIA.TA; TVD6.F; 26Y.SG; HOC.F; YTRA; HSW.F; 1TJ.F; HSW.IR; 1235.HK; HOC.DE; TXM1.F; 8668.HK; TRZ.TO; TZOO; ID9.F; 8069.HK; COX&KINGS.NS; TRRB; VMV.BO; COX&KINGS.BO; 1620.HK; 1701.HK; 0TUA.F; HLO.AX; 6882.HK; ALVDM.PA; 09B.F; TOUR; 2719.TWO; ITHL.BO; LMN.SW; 1901.HK; EDR.MC; MIN.L; 8095.HK; 2743.TWO; 2745.TWO; 0487.HK; 2734.TWO; LI4.F; 9BP.F; D3G.F; LIND; 0265.HK; DESP; 6242.TWO; ISTA.TA; WBJ.F; 600706.SS; 6T8.F; 1C6.F; 1745.HK; WEB.AX; 9376.T; 300178.SZ; MY1.F; 002159.SZ; FLI.F; 603099.SS; 603199.SS; 2T9A.F; 5706.TW; CTD.AX; MMYT; DG1.F; DRTGF; MMB.PA; 6577.T; NTHOL.IS; LAG.F; 000888.SZ; FLT.AX; WD5A.F; TEM.F; 1810.SR; TEM.DU; CVCB3.SA; 300859.SZ; TUI2.F; 6548.T; TUI2.SG; TUI1.F; TUI1.DE; 002707.SZ; TNL; TRIP.MI; T6A.F; T6A.DE; TRIP.VI; TUIFF; 2731.TW; TUIFY; TRIP; TENG.L; NCLH.VI; 1NC.F; 000796.SZ; 6561.T; NCLH; 9085.S; THOMASCOOK.BO; HSW.L; 1992.HK; PGJO.JK; RC8.F; THOMASCOOK.NS; CLV.F; 7048.T; RCL; EXPE.VI; E3X1.F; TCOM; EXPE; CVC1.F; 9726.T; CCL; T1RI34.SA; YELO.JK; 6030.T; 0780.HK; 6191.T; N1CL34.SA; OTB.L; BOOK.VI; PCE1.F; DESP.BA; BKNG; R1CL34.SA; TRIP.MX; EXGR34.SA; CRIP34.SA; NCLHN.MX; C1CL34.SA; PANR.JK; PDES.JK; TRN.L; JET2.L; BAYU.JK; RCL.MX; TUI.L; EXPE.MX; BKNG34.SA; 601888.SS; TRIP.BA; 039130.KS; 032350.KS; SONA.JK; BKNG.MX; '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = ''\n",
    "for k in travel_dict.keys():\n",
    "    t = k + '; ' + t\n",
    "\n",
    "print(len(travel_dict.keys()))\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue: Without Region \n",
    "\n",
    "[Solution](https://github.com/lowspace/MAST90106/blob/main/code/Yahoo%20Finance%20Profile%20Page.ipynb): crawl profile page of each company, and security our fliter.\n",
    "\n",
    "REF1: https://info.cloudquant.com/2019/07/url2symbol/  \n",
    "REF2: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find\n",
    "\n",
    "Issue in there:\n",
    "+ some websites donot have a profile yet, such as:\n",
    "    + https://finance.yahoo.com/quote/GMLPP/profile?p=GMLPP\n",
    "    + https://finance.yahoo.com/quote/LAG.SG/profile?p=LAG.SG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "\n",
    "<a name=\"ft1\">[1]</a>: How to acess Yahoo Fiance data remotely? (Chinese Version) https://blog.csdn.net/Hellolijunshy/article/details/82527643\n",
    "\n",
    "<a name=\"ft2\">[2]</a>: Getting KeyError : 'Date' in Yahoo https://github.com/pydata/pandas-datareader/issues/640"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "原始单元格格式",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
